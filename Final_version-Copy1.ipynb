{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce707b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "539f22f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                track_id                 artists  \\\n",
      "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
      "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
      "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
      "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
      "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
      "\n",
      "                                          album_name  \\\n",
      "0                                             Comedy   \n",
      "1                                   Ghost (Acoustic)   \n",
      "2                                     To Begin Again   \n",
      "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
      "4                                            Hold On   \n",
      "\n",
      "                   track_name  popularity  duration_ms  explicit  \\\n",
      "0                      Comedy          73       230666     False   \n",
      "1            Ghost - Acoustic          55       149610     False   \n",
      "2              To Begin Again          57       210826     False   \n",
      "3  Can't Help Falling In Love          71       201933     False   \n",
      "4                     Hold On          82       198853     False   \n",
      "\n",
      "   danceability  energy  ...  loudness  mode  speechiness  acousticness  \\\n",
      "0         0.676  0.4610  ...    -6.746     0       0.1430        0.0322   \n",
      "1         0.420  0.1660  ...   -17.235     1       0.0763        0.9240   \n",
      "2         0.438  0.3590  ...    -9.734     1       0.0557        0.2100   \n",
      "3         0.266  0.0596  ...   -18.515     1       0.0363        0.9050   \n",
      "4         0.618  0.4430  ...    -9.681     1       0.0526        0.4690   \n",
      "\n",
      "   instrumentalness  liveness  valence    tempo  time_signature  track_genre  \n",
      "0          0.000001    0.3580    0.715   87.917               4     acoustic  \n",
      "1          0.000006    0.1010    0.267   77.489               4     acoustic  \n",
      "2          0.000000    0.1170    0.120   76.332               4     acoustic  \n",
      "3          0.000071    0.1320    0.143  181.740               3     acoustic  \n",
      "4          0.000000    0.0829    0.167  119.949               4     acoustic  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('spotify_dataset.csv')\n",
    "\n",
    "# Display the first few rows to understand its structure\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e220a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fine-tune a BERT model for sequence classification\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48239164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess textual data\n",
    "def preprocess_text(df, text_columns):\n",
    "    for col in text_columns:\n",
    "        df[col] = df[col].fillna('unknown')  # Fill missing values with 'unknown'\n",
    "        df[col] = df[col].astype(str).str.lower()  # Convert to lowercase and ensure string\n",
    "        df[col] = df[col].apply(lambda x: re.sub(r'[\\W_]+', ' ', x))  # Remove special characters\n",
    "    df['combined_text'] = df[text_columns].apply(lambda x: ' '.join(x), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0303c2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  track_genre  track_genre_encoded\n",
      "0    acoustic                    0\n",
      "1    acoustic                    0\n",
      "2    acoustic                    0\n",
      "3    acoustic                    0\n",
      "4    acoustic                    0\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with a placeholder string, such as 'Unknown'\n",
    "df['track_genre'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Check unique genres\n",
    "unique_genres = df['track_genre'].unique()\n",
    "\n",
    "# Create a mapping from genre to an integer\n",
    "genre_to_int = {genre: i for i, genre in enumerate(unique_genres)}\n",
    "\n",
    "# Add a new column to the dataframe with the encoded numerical values\n",
    "df['track_genre_encoded'] = df['track_genre'].map(genre_to_int)\n",
    "\n",
    "# Now df has an additional column 'track_genre_encoded' with numerical values representing the genres\n",
    "print(df[['track_genre', 'track_genre_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9b1e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_labels = {genre: idx for idx, genre in enumerate(df['track_genre'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "640d3c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acoustic': 0,\n",
       " 'afrobeat': 1,\n",
       " 'alt-rock': 2,\n",
       " 'alternative': 3,\n",
       " 'ambient': 4,\n",
       " 'anime': 5,\n",
       " 'black-metal': 6,\n",
       " 'bluegrass': 7,\n",
       " 'blues': 8,\n",
       " 'brazil': 9,\n",
       " 'breakbeat': 10,\n",
       " 'british': 11,\n",
       " 'cantopop': 12,\n",
       " 'chicago-house': 13,\n",
       " 'children': 14,\n",
       " 'chill': 15,\n",
       " 'classical': 16,\n",
       " 'club': 17,\n",
       " 'comedy': 18,\n",
       " 'country': 19,\n",
       " 'dance': 20,\n",
       " 'dancehall': 21,\n",
       " 'death-metal': 22,\n",
       " 'deep-house': 23,\n",
       " 'detroit-techno': 24,\n",
       " 'disco': 25,\n",
       " 'disney': 26,\n",
       " 'drum-and-bass': 27,\n",
       " 'dub': 28,\n",
       " 'dubstep': 29,\n",
       " 'edm': 30,\n",
       " 'electro': 31,\n",
       " 'electronic': 32,\n",
       " 'emo': 33,\n",
       " 'folk': 34,\n",
       " 'forro': 35,\n",
       " 'french': 36,\n",
       " 'funk': 37,\n",
       " 'garage': 38,\n",
       " 'german': 39,\n",
       " 'gospel': 40,\n",
       " 'goth': 41,\n",
       " 'grindcore': 42,\n",
       " 'groove': 43,\n",
       " 'grunge': 44,\n",
       " 'guitar': 45,\n",
       " 'happy': 46,\n",
       " 'hard-rock': 47,\n",
       " 'hardcore': 48,\n",
       " 'hardstyle': 49,\n",
       " 'heavy-metal': 50,\n",
       " 'hip-hop': 51,\n",
       " 'honky-tonk': 52,\n",
       " 'house': 53,\n",
       " 'idm': 54,\n",
       " 'indian': 55,\n",
       " 'indie-pop': 56,\n",
       " 'indie': 57,\n",
       " 'industrial': 58,\n",
       " 'iranian': 59,\n",
       " 'j-dance': 60,\n",
       " 'j-idol': 61,\n",
       " 'j-pop': 62,\n",
       " 'j-rock': 63,\n",
       " 'jazz': 64,\n",
       " 'k-pop': 65,\n",
       " 'kids': 66,\n",
       " 'latin': 67,\n",
       " 'latino': 68,\n",
       " 'malay': 69,\n",
       " 'mandopop': 70,\n",
       " 'metal': 71,\n",
       " 'metalcore': 72,\n",
       " 'minimal-techno': 73,\n",
       " 'mpb': 74,\n",
       " 'new-age': 75,\n",
       " 'opera': 76,\n",
       " 'pagode': 77,\n",
       " 'party': 78,\n",
       " 'piano': 79,\n",
       " 'pop-film': 80,\n",
       " 'pop': 81,\n",
       " 'power-pop': 82,\n",
       " 'progressive-house': 83,\n",
       " 'psych-rock': 84,\n",
       " 'punk-rock': 85,\n",
       " 'punk': 86,\n",
       " 'r-n-b': 87,\n",
       " 'reggae': 88,\n",
       " 'reggaeton': 89,\n",
       " 'rock-n-roll': 90,\n",
       " 'rock': 91,\n",
       " 'rockabilly': 92,\n",
       " 'romance': 93,\n",
       " 'sad': 94,\n",
       " 'salsa': 95,\n",
       " 'samba': 96,\n",
       " 'sertanejo': 97,\n",
       " 'show-tunes': 98,\n",
       " 'singer-songwriter': 99,\n",
       " 'ska': 100,\n",
       " 'sleep': 101,\n",
       " 'songwriter': 102,\n",
       " 'soul': 103,\n",
       " 'spanish': 104,\n",
       " 'study': 105,\n",
       " 'swedish': 106,\n",
       " 'synth-pop': 107,\n",
       " 'tango': 108,\n",
       " 'techno': 109,\n",
       " 'trance': 110,\n",
       " 'trip-hop': 111,\n",
       " 'turkish': 112,\n",
       " 'world-music': 113}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaac6647",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = ['artists', 'album_name', 'track_name']\n",
    "data = preprocess_text(df, text_columns)\n",
    "\n",
    "# Preprocess numerical features\n",
    "numerical_columns = ['danceability', 'energy', 'loudness', 'speechiness',\n",
    "                     'acousticness', 'liveness', 'instrumentalness', 'valence', 'tempo']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Split data into train and validation sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(data['combined_text'], df['track_genre_encoded'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c702f32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['combined_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a28179c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_list = [\"\".join(map(str, row)) for row in data['combined_text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6ed95e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "class SongDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels  # You might use 'track_genre' as labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')    \n",
    "    \n",
    "\n",
    "labels = df['track_genre_encoded']  # Convert genres to numerical labels\n",
    "\n",
    "encodings = tokenizer(input_text_list, truncation=True, padding=True, max_length=512)\n",
    "dataset = SongDataset(encodings, labels)\n",
    "\n",
    "# Fine-tune BERT (simplified example)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de6f624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorize genres and keep the unique genre names\n",
    "labels, unique_genres = df['track_genre'].factorize()\n",
    "\n",
    "# Create a mapping from numerical labels back to genre names\n",
    "genre_mapping = {index: genre for index, genre in enumerate(unique_genres)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2)\n",
    "\n",
    "# Create a DataLoader for both training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Load the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(genre_to_int))\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if a GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Now you can send the model to the specified device\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "model.to(device)  # Send the model to the GPU if available\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "epochs = 3\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(train_loader) * epochs)\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # Train the data for one epoch\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    \n",
    "    for batch in tqdm(val_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**batch)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = batch['labels'].to('cpu').numpy()\n",
    "        \n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    \n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
    "    print(f\"Training loss: {avg_train_loss}\")\n",
    "    print(f\"Validation accuracy: {avg_val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "689a684d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['bert.embeddings.position_ids'], unexpected_keys=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model state dictionary with mapping to CPU\n",
    "model.load_state_dict(torch.load('mymodel1', map_location=torch.device('cpu')), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a985df24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=114, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713c8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your music preference or 'exit' to quit: pop songs\n",
      "\n",
      "Here are some top 5 recommendations for you:\n",
      "1. \u001b[1mi wanna be yours\u001b[0m by arctic monkeys\n",
      "\n",
      "2. \u001b[1mbillie eilish \u001b[0m by armani white\n",
      "\n",
      "3. \u001b[1mi love you so\u001b[0m by the walters\n",
      "\n",
      "4. \u001b[1mdo i wanna know \u001b[0m by arctic monkeys\n",
      "\n",
      "5. \u001b[1m505\u001b[0m by arctic monkeys\n",
      "\n",
      "Enter your music preference or 'exit' to quit: pop songs of billie eilish\n",
      "\n",
      "Here are some top 5 recommendations for you:\n",
      "1. \u001b[1mone kiss with dua lipa \u001b[0m by calvin harris dua lipa\n",
      "\n",
      "2. \u001b[1mnumb\u001b[0m by marshmello khalid\n",
      "\n",
      "3. \u001b[1mbad decisions with bts snoop dogg \u001b[0m by benny blanco bts snoop dogg\n",
      "\n",
      "4. \u001b[1mbelly dancer\u001b[0m by imanbek byor\n",
      "\n",
      "5. \u001b[1meverything i wanted\u001b[0m by billie eilish\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def recommend_song(query):\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    \n",
    "    genre_predicted = genre_mapping[predictions.item()]\n",
    "    \n",
    "    # Filter the DataFrame for the predicted genre and choose the top 5 popular songs\n",
    "    recommended_songs = df[df['track_genre'] == genre_predicted].sort_values(by='popularity', ascending=False).head(5)\n",
    "    \n",
    "    # Return the top 5 songs as a list of tuples (track_name, artist)\n",
    "    return [(row['track_name'], row['artists']) for index, row in recommended_songs.iterrows()]\n",
    "\n",
    "# Interactive loop to get recommendations\n",
    "while True:\n",
    "    query = input(\"Enter your music preference or 'exit' to quit: \")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "    \n",
    "    top_songs = recommend_song(query)\n",
    "    print(\"\\nHere are some top 5 recommendations for you:\")\n",
    "    for i, (song, artist) in enumerate(top_songs, start=1):\n",
    "        #print(f\"{i}. {song} by {artist}\")\n",
    "        print(f\"{i}. \\033[1m{song}\\033[0m by {artist}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618d2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
